#!/usr/bin/env python

# Note this script is adapted version is an adapted version of the original
# MillenniumDB regular-path-query challenge benchmark script.
#
# See !!!

import os
import re
import socket
import subprocess
import time
import argparse as ap

p = ap.ArgumentParser(description='Run and benchmark MillenniumDB')

p.add_argument('bin', help='MillenniumDB binary dir')
p.add_argument('database', help='Database directory')
p.add_argument('queries', help='Queries file or directory')
p.add_argument('--heatup', help='Whether to perform heatup run (default: enabled)', default=True, action=ap.BooleanOptionalAction)
p.add_argument('--timeout', type=int, help='Query timeout in seconds (default: 60)', default=60)
p.add_argument('--limit', type=int, help='Query answer limit (default: 100000000', default=100000000)
p.add_argument('--count', type=int, help='How many times to bench the dataset (default: 1)', default=1)
p.add_argument('--results', help='Results directory name (default: results/)', default='results')
p.add_argument('--port', type=int, help='MillenniumDB port (default: 1234)', default=1234)

args = p.parse_args()

MDB_PATH = f'.' # where you cloned MillenniumDB repo
OUTPUT_PATH = f'./{args.results}'   # results and logs will be written here, folder must exist
MDB_DB_FOLDER_PATH = f'{args.database}' # database folder

os.makedirs(OUTPUT_PATH, exist_ok=True)

# Buffer used by MillenniumDB 8388608 pages(4kB) == 32GB
# this is only for the buffer manager (B+Tree pages),
# MillenniumDB will use more RAM for other things (tries/visited hashmaps)
#BUFFER_SIZE = 10000000
BUFFER_SIZE = 1000
STRING_POPULATE_SIZE = 1

MDB_PORT = args.port


# Previously provided parameters were
#           '-b', str(BUFFER_SIZE),
#           '-s', str(STRING_POPULATE_SIZE),
#           '-l', str(args.limit)

MDB_CMD = [f'{args.bin}/mdb-server',
           MDB_DB_FOLDER_PATH,
           '--timeout', str(args.timeout),
           ]

print(" ".join(MDB_CMD))


# Path to needed output and input files #
MDB_QUERY_FILE   = f'{OUTPUT_PATH}/query_file.tmp'
MDB_RESULTS_FILE = f'{OUTPUT_PATH}/.results.tmp'
SERVER_LOG_FILE  = f'{OUTPUT_PATH}/mdb_paths.log'
RESULTS_FILE  = f'{OUTPUT_PATH}/results.csv'

# Does not return a string, it writes the query in MDB_QUERY_FILE
# Designed to work for WDBench queries, not a generic SPARQL property path
def parse_to_millenniumdb(query):
    with open(MDB_QUERY_FILE, 'w') as file:
        file.write(f'select ?x1 where {{ {query.replace("?sub", "?x1").replace("?obj", "?x1")} }}')


def start_server():
    global server_process
    os.chdir(MDB_PATH)
    print('starting server...')

    server_log.write("[start server]\n")
    server_process = subprocess.Popen(MDB_CMD, stdout=server_log, stderr=server_log)
    print(f'pid: {server_process.pid}')

    # Sleep to wait server start
    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    location = ("127.0.0.1", MDB_PORT)
    while s.connect_ex(location) != 0:
        time.sleep(1)

    print(f'done')


def kill_server():
    global server_process
    print(f'killing server[{server_process.pid}]...')
    server_process.kill()
    server_process.wait()
    print('done')


def query_millennium(query, query_number, second=False):
    parse_to_millenniumdb(query)
    start_time = time.time()
    with open(MDB_RESULTS_FILE, 'w') as results_file:
        query_execution = subprocess.Popen(
            ['./query',
             MDB_QUERY_FILE],
            stdout=results_file,
            stderr=subprocess.DEVNULL)
        exit_code = query_execution.wait()

def check_port_available():
    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    location = ("127.0.0.1", MDB_PORT)
    # Check if port is already in use
    if s.connect_ex(location) == 0:
        raise Exception("server port already in use")

def process_results(output_name):
    results_path = f'results/'
    output_path = f'{results_path}/{output_name}.csv'
    os.makedirs(results_path, exist_ok=True)
    with open(SERVER_LOG_FILE, 'r') as server_log, open(output_path, 'w') as results_file:
        k = 1
        results = 0
        time = 0
        results_file.write(f'query,time,results\n')
        for i in server_log:
            print(i)
            if i.startswith('Execution'):
                v = float(i.split(' : ')[1][:-4])
                time += int(v * 1000)
                results_file.write(f'{k},{time},{results}\n')
                k = k + 1
            elif i.startswith('Optimizer'):
                v = float(i.split(' : ')[1][:-4])
                time = int(v * 1000)
            elif i.startswith('Results '):
                v = int(i.split(' : ')[1])
                results = v
            elif i.startswith('Timeout'):
                results_file.write(f'{k},timeouted\n')
                k = k + 1

def execute_file(queries):
    heatup = args.heatup
    count = args.count

    print('Running file...')
    if heatup:
        print('Loading query data into the cache...')
        with open(queries) as queries_file:
            for line in queries_file:
                query_number, query = line.split(',', 1)
                query_millennium(query, query_number, second=True)

    print('Required data has been loaded')
    for i in range(count):
        with open(queries) as queries_file:
            for line in queries_file:
                query_number, query = line.split(',', 1)
                print(f'Executing query {query_number}')
                query_millennium(query, query_number, second=True)

    process_results(os.path.basename(queries))
    server_log.truncate(0)

def execute_dir(queries_dir):
    with os.scandir(queries_dir) as it:
        for entry in it:
            if entry.is_file():
                execute_file(entry.path)

def execute_queries():
    queries = args.queries
    if os.path.isdir(queries):
        execute_dir(queries)
    else:
        execute_file(queries)

########################## BEGIN BENCHMARK EXECUTION ##########################
server_log = open(SERVER_LOG_FILE, 'w')
server_process = None

check_port_available()

try:
    start_server()
    execute_queries()

    server_log.close()
finally:
    if server_process is not None:
        max_mem_cmd = f'grep ^VmHWM /proc/{server_process.pid}/status'.split(' ')
        process = subprocess.Popen(max_mem_cmd, universal_newlines=True, stdout=subprocess.PIPE)
        out, err = process.communicate()
        print(out)
        kill_server()

